{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport seaborn as sn\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nimport numpy as np\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing import sequence\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding, Flatten, Add, Conv1D, Layer\nfrom tensorflow.keras.optimizers import RMSprop, Adam, Adadelta, Adagrad, Adamax, Ftrl, Nadam, SGD\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nfrom tensorflow.keras.metrics import Accuracy\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.losses import CategoricalCrossentropy\nfrom scipy.signal import savgol_filter\nimport matplotlib.pyplot as plt\nfrom tensorflow_addons.metrics import F1Score\nfrom tensorflow_addons.optimizers import AdamW\nfrom tensorflow_addons.losses import SigmoidFocalCrossEntropy\nfrom transformers import AutoTokenizer, TFAutoModel, AutoModelForSequenceClassification, TFAutoModelForSequenceClassification\nfrom tensorflow.nn import softmax as tf_softmax\nimport nltk\nfrom nltk.stem import WordNetLemmatizer \n%matplotlib inline","metadata":{"_uuid":"46050add-e2a2-4e20-b201-fde971f80b7c","_cell_guid":"e870a855-d099-41fb-a272-54658c3160d2","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def is_interactive():\n    return 'runtime' in get_ipython().config.IPKernelApp.connection_file\n\nprint('Interactive: ', is_interactive())","metadata":{"_uuid":"9b371772-28d1-4a95-8c7e-ecb3cda3d10f","_cell_guid":"e66985f2-cd11-4714-b113-7cfe05c620a9","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Detect hardware, return appropriate distribution strategy\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n    print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n    strategy = tf.distribute.get_strategy()\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","metadata":{"_uuid":"54e5bf64-06cf-4cf6-af87-4f0ac2163f66","_cell_guid":"d395e4a4-d005-4a6a-b8d6-586ec6dddc50","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"task = 'c' # a,b,c\nkeys_for_task = {'a':'label_sexist','b':'label_category','c':'label_vector'}\nkey_for_task = keys_for_task[task]","metadata":{"_uuid":"a30e54ae-b1b7-4fe2-90e7-96ed1862a8dd","_cell_guid":"80545b5f-8236-466e-be37-e6ad62c71a36","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **DATA PREPROCESSING**","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/explainable-detection-of-online-sexism-edos/starting_kit/train_all_tasks.csv',delimiter=',',encoding='utf-8')\ndf.head()","metadata":{"_uuid":"5067659a-e4af-49a1-97ca-f8adbc3f4e0e","_cell_guid":"86e5eb03-61aa-43e3-9bfe-e7dfab3cf914","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nltk.download('wordnet')\nnltk.download('omw-1.4')\n\nlemmatizer = WordNetLemmatizer()\n\ndef lemmatize(sentence):\n    return ' '.join([lemmatizer.lemmatize(word) for word in sentence.split(' ')])","metadata":{"_uuid":"a715388d-acf9-4c82-9faa-b3f223730d76","_cell_guid":"e05417a3-39a3-4345-a96e-79211c8d9522","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['text'] = df['text'].map(lambda sentence:lemmatize(sentence))\ndf.head()","metadata":{"_uuid":"ad970a6a-df6b-4c35-8ab4-a74424c39805","_cell_guid":"c2d11a6c-bc73-42ca-8313-593851546b2f","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.drop(['rewire_id'],axis=1,inplace=True)\ndf.head()","metadata":{"_uuid":"022e13f2-bd6e-41fc-b1a3-409fb32702d7","_cell_guid":"9b5ab4f5-32c7-4c0b-b72a-6e55eedb47ea","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def count_plot(df, name, key_count = key_for_task):\n    print(df.info())\n    sn.countplot(data=df, x=key_count)\n    plt.xticks(rotation = 90)\n    plt.savefig(name)\n    plt.show()\n    \ncount_plot(df,\"distribution.svg\")","metadata":{"_uuid":"11d21e4b-360c-4342-aec0-0abb526bbdfc","_cell_guid":"152af22e-c8d3-49ce-9174-c8ee58ab56a5","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lens = df.text.str.len().value_counts()\ncount_plot = pd.DataFrame({'leng':lens.index, 'freq':lens.values}).sort_values('leng')\nplt.plot(count_plot.leng,count_plot.freq)\nplt.plot(count_plot.leng,savgol_filter(count_plot.freq, 51, 3), color='red')\nplt.xlabel('Length')\nplt.ylabel('Frequency')\nplt.show()","metadata":{"_uuid":"9c12c859-bf64-4d82-b208-2d5235e86b91","_cell_guid":"fd048154-fc88-4994-bcaf-e521949e8477","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **LABEL ENCODING**","metadata":{}},{"cell_type":"code","source":"label_encoder = LabelEncoder()\n\n# label encoding\n\nX = df['text']\nY = df[key_for_task]\nY = label_encoder.fit_transform(Y)","metadata":{"_uuid":"2dbeaaf4-0185-4b29-a12e-a06d6a9848b8","_cell_guid":"b72d1196-fdd6-48ed-85b6-9ebfb2741d1f","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_encoder_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\nprint(label_encoder_mapping)\ninverse_label_encoder_mapping = {label_encoder_mapping[k]:k for k in label_encoder_mapping}\nprint(inverse_label_encoder_mapping)\n\nNUM_CLASS = len(label_encoder_mapping)","metadata":{"_uuid":"3844acfa-cc1d-4110-91fa-625384edc916","_cell_guid":"5d00a9ff-0b9b-486b-bdda-923e7025224e","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# one hot encoding\n\nY = tf.keras.utils.to_categorical(Y, num_classes=NUM_CLASS)","metadata":{"_uuid":"fc3b83c8-747b-421a-ab91-b34490acddd5","_cell_guid":"ec3e16d9-694e-4bcb-9265-d95159d1096f","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DEBUG_EPOCH = 20 \n\nEPOCH = DEBUG_EPOCH if is_interactive() else 180\nprint(EPOCH)\n\nLEARNING_RATE = 5e-5\nWEIGHT_DECAY = 1e-2","metadata":{"_uuid":"5365a424-b640-49be-9dd9-0347b3fe7f27","_cell_guid":"18f7b695-7535-498f-b40f-047fc3160b17","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **SENTENCE TRANSFORMATION**","metadata":{}},{"cell_type":"code","source":"# \"sentence-transformers/all-MiniLM-L6-v2\"\n## https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2\n\nclass Sentence2Sentence(Layer):\n    def __init__(self, **kwargs):\n        super(Sentence2Sentence, self).__init__(**kwargs)\n\n        pre_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n        self.tokenizer = AutoTokenizer.from_pretrained(pre_name)\n        self.model = TFAutoModel.from_pretrained(pre_name)\n\n        \n    def tf_encode(self, inputs):\n        def encode(inputs):\n            inputs = [x[0].decode('utf-8') for x in inputs.numpy()]\n            outputs = self.tokenizer(inputs, padding=True, truncation=True, return_tensors='tf')\n            return (outputs['input_ids'], outputs['token_type_ids'], outputs['attention_mask'])\n\n        return tf.py_function(func=encode, inp=[inputs], Tout=[tf.int32, tf.int32, tf.int32])\n\n    def process(self,i,t,a):\n\n        def __call(i, t, a):\n            model_output = self.model({'input_ids': i.numpy(),'token_type_ids': t.numpy(),'attention_mask': a.numpy()})\n            return model_output[0]\n\n        return tf.py_function(func=__call, inp=[i, t, a], Tout=[tf.float32])\n\n    def mean_pooling(self, model_output, attention_mask):\n        token_embeddings = tf.squeeze(tf.stack(model_output), axis=0)\n        input_mask_expanded = tf.cast(tf.broadcast_to(tf.expand_dims(attention_mask, -1),tf.shape(token_embeddings)), tf.float32)\n        a = tf.math.reduce_sum(token_embeddings * input_mask_expanded, axis=1)\n        b = tf.clip_by_value(tf.math.reduce_sum(input_mask_expanded, axis=1), 1e-9, tf.float32.max)\n        embeddings = a / b\n        (embeddings, _) = tf.linalg.normalize(embeddings, 2, axis=1)\n        return embeddings\n\n    def call(self, inputs):\n        (input_ids, token_type_ids, attention_mask) = self.tf_encode(inputs)\n        input_ids.set_shape(tf.TensorShape((None, None)))\n        token_type_ids.set_shape(tf.TensorShape((None, None)))\n        attention_mask.set_shape(tf.TensorShape((None, None)))\n\n        model_output = self.process(input_ids, token_type_ids,attention_mask)\n        \n        model_output[0].set_shape(tf.TensorShape((None, None, 384)))\n        embeddings = self.mean_pooling(model_output, attention_mask)\n        # Reshape embeddings to have a third dimension\n        embeddings = tf.expand_dims(embeddings, axis=-1)\n        return embeddings","metadata":{"_uuid":"6a06e8c9-999b-451b-af53-72e3839e53cf","_cell_guid":"f218c994-657f-4e1c-a710-920061fa1e02","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class StringLowerLayer(Layer):\n    def __init__(self, **kwargs):\n        super(StringLowerLayer, self).__init__(**kwargs)\n        \n    def call(self, inputs):\n        return tf.strings.lower(inputs)","metadata":{"_uuid":"8d8cde2e-add6-4388-8284-4b6503ead530","_cell_guid":"d873bebb-a9b7-4acb-9766-55959c25fa3d","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class StressLayer(Layer):\n    def __init__(self, **kwargs):\n        super(StressLayer, self).__init__(**kwargs)","metadata":{"_uuid":"1fc53186-a541-4919-aa86-5ec14c0e1561","_cell_guid":"46047f3c-e09e-47cd-aadb-7e9bdd55bffa","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **MODEL ARCHITECTURE**","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, Dropout\nfrom tensorflow.keras.models import Model\n\ndef get_model():\n    # Input layer\n    input_layer = Input(shape=(1,), dtype=tf.string,)\n    sentence_layer = Sentence2Sentence()(input_layer)\n    \n    # Convolutional layers\n    conv1 = Conv1D(filters=128, kernel_size=5, activation='relu')(sentence_layer)\n    pool1 = MaxPooling1D(pool_size=2)(conv1)\n    conv2 = Conv1D(filters=64, kernel_size=3, activation='relu')(pool1)\n    pool2 = MaxPooling1D(pool_size=2)(conv2)\n    conv3 = Conv1D(filters=32, kernel_size=2, activation='relu')(pool2)\n    pool3 = MaxPooling1D(pool_size=2)(conv3)\n\n    # Flatten layer\n    flatten_layer = Flatten()(pool3)\n\n    # Dense layers\n    dense1 = Dense(128, activation='relu')(flatten_layer)\n    dropout1 = Dropout(0.5)(dense1)\n    dense2 = Dense(64, activation='relu')(dropout1)\n    dropout2 = Dropout(0.5)(dense2)\n    output_layer = Dense(NUM_CLASS, activation='softmax')(dropout2)\n\n    model = Model(inputs=input_layer, outputs=output_layer)\n    optimizer = Adam(learning_rate=LEARNING_RATE)\n    model.compile(\n        loss='binary_crossentropy',\n        optimizer=optimizer,\n        metrics=['accuracy',\n            F1Score(num_classes=NUM_CLASS,average='weighted'),\n        ],\n    )\n    \n    return model","metadata":{"_uuid":"f70c57eb-7951-4fd4-b82f-096af4f0b4df","_cell_guid":"375a16c2-7e73-4e5e-8d22-8ffa01936675","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = get_model()","metadata":{"_uuid":"787587a2-1545-488e-b04f-c98fddd7d01d","_cell_guid":"4dabb078-281c-4165-9acc-0e9f81d9c642","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"_uuid":"942b21f7-6e04-4cc6-9332-fc76be093ab5","_cell_guid":"52fad67a-35ea-421b-81a1-32e41785e52e","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.utils.plot_model(model, to_file='model.png',expand_nested=True,show_shapes=True,dpi=None,)","metadata":{"_uuid":"2b243ebd-c01d-42f1-b2ee-840c9b06e7b0","_cell_guid":"79c07c09-4944-4f09-8602-ca872f5ccc25","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **SPLIT AND REGULARIZATION**","metadata":{}},{"cell_type":"code","source":"lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.1,patience=10)\nearly_stopping_callback = EarlyStopping(monitor='val_loss',min_delta=0,patience=30,verbose=0, mode='auto')\nmodel_saver = ModelCheckpoint(filepath='model.h5', save_best_only=True)\n\ncallbacks = [early_stopping_callback, lr_reducer,model_saver]","metadata":{"_uuid":"6dc0a7e4-d0f4-4ef6-9073-3b201c71be3c","_cell_guid":"16ff16a6-7874-4651-b310-270f324ff2ed","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SHUFFLE_DS = 1024\nBATCH_SIZE_DS = 16 * strategy.num_replicas_in_sync\nAUTO = tf.data.experimental.AUTOTUNE\n\nif task == 'a':\n    train_X, val_X, train_Y, val_Y = train_test_split(X, Y, test_size=0.3, stratify=Y)\nelse:\n    train_X, val_X, train_Y, val_Y = train_test_split(X, Y, test_size=0.3)\n\n\n# train_ds = tf.data.Dataset.from_tensor_slices((train_X, train_Y)).repeat().shuffle(SHUFFLE_DS).batch(BATCH_SIZE_DS).prefetch(AUTO)\n# val_ds = tf.data.Dataset.from_tensor_slices((val_X, val_Y)).repeat().shuffle(SHUFFLE_DS).batch(BATCH_SIZE_DS).prefetch(AUTO)\n    \nN_STEPS = len(train_X) / BATCH_SIZE_DS","metadata":{"_uuid":"d57ca36a-5729-4ff4-a0be-4cfc83cdcd5d","_cell_guid":"5ca16cbc-eda4-4bea-8659-e4a1eb05cb8e","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **MODEL INFERENCE**","metadata":{}},{"cell_type":"code","source":"history_model = model.fit(train_X, train_Y,epochs=EPOCH,validation_data=(val_X, val_Y), callbacks=callbacks, steps_per_epoch = N_STEPS)","metadata":{"_uuid":"5fdfff8e-a358-4f09-b6d0-f0799692edea","_cell_guid":"a22b85d1-aff2-46aa-a8e1-8ba56dde321e","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir history","metadata":{"_uuid":"c3365e26-23d0-4dfa-8478-9382a74f188b","_cell_guid":"d37cf5d3-1201-4ca1-acee-52c4f417149a","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('history/history.json','w') as f:\n    f.write(str(history_model.history))","metadata":{"_uuid":"c83f7309-f9af-44d0-b68a-10a635d53c25","_cell_guid":"1d3056af-be18-46cf-9cdf-5aeb7a88ee96","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir figures","metadata":{"_uuid":"343f02dd-be18-40b9-a39e-31df82ba32ec","_cell_guid":"f5350b56-1442-45bf-869f-c32e6f8e5139","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def captilize(string):\n    string = string.replace(\"_\",\" \")\n    return string.title()\n    \n    \ndef plot_graphs(data, keys):\n    fig, axes = plt.subplots(1, (len(keys) + 1) , figsize=(16, 5))\n    plt.legend(loc='best')\n    \n    for i in range(len(keys)):\n        df_graph = pd.DataFrame({x:data[x] for x in data if keys[i] in x})\n        df_keys = [x for x in data if keys[i] in x]\n        df_graph[df_keys].plot(ax=axes[i])\n        axes[i].set_title(captilize(keys[i]))\n        \n    last_index = len(keys)\n    all_keys = [x for x in data if x]\n    \n    df_combined = pd.DataFrame({x: data[x] for x in data})\n    df_combined[all_keys].plot(ax=axes[last_index])\n    axes[len(keys)].set_title('Combined')\n    \n    plt.tight_layout()\n    \n    plt.savefig('figures/figure_optimizer.svg')\n    plt.show()\n        \nplot_graphs(data = history_model.history, keys= ['f1_score','loss', 'lr'])","metadata":{"_uuid":"5cc7bc31-dd0c-48e7-b2da-e86901655ec4","_cell_guid":"2fc8322d-7ce1-4550-9442-1bd9feb6540f","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}